{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import picamera\n",
    "from threading import Thread\n",
    "from multiprocessing import Process\n",
    "from queue import Queue, Empty\n",
    "from time import time, sleep\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOutput():\n",
    "    '''\n",
    "    Class used by PiCamera object to record the frames coming from the camera. \n",
    "    \n",
    "    The PiCamera class assumes there is a write method (and optionally a flush method).\n",
    "    Since we've got to pass the data to the image processor by the means of a queue and \n",
    "    since we are actually recording data (not taking photos), setting markers for an individual\n",
    "    frame is rather troublesome - the solution is to define a custom output class.\n",
    "    \n",
    "    Check https://picamera.readthedocs.io/en/release-1.13/recipes2.html#custom-outputs\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, queue, resolution, state):\n",
    "        '''\n",
    "        Initialize MyOutput object.\n",
    "        \n",
    "        Init params:\n",
    "        queue -- The queue onto which raw frames are pushed to.\n",
    "        resolution -- The resolution of the pushed frames. 2-element tuple of (width, height).\n",
    "        state -- A dictionary containing important markers about the current frame: time, red/blue/green GB; TL;DR metadata.\n",
    "        '''\n",
    "        self._queue = queue\n",
    "        self._resolution = resolution[::-1] + (3,)\n",
    "        self._state = state\n",
    "        self.decouple_queue = False\n",
    "    \n",
    "    def write(self, s):\n",
    "        '''\n",
    "        Write method required by PiCamera class.\n",
    "        \n",
    "        Keyword params:\n",
    "        s -- A bytes object containing the actual image that got captured.\n",
    "        '''\n",
    "        self._buffer = np.frombuffer(s, np.uint8).reshape(*self._resolution)\n",
    "        self.flush()\n",
    "    \n",
    "    def flush(self):\n",
    "        '''\n",
    "        Flush method that needs to be called to push the data to the queue. \n",
    "        Apart from being called by write method every time, it also gets called at the end of the recording by the PiCamera object.\n",
    "        '''\n",
    "        \n",
    "        if self.decouple_queue is False and self._buffer is not None:\n",
    "            self._queue.put([\n",
    "                self._buffer,\n",
    "                self._state\n",
    "            ], block = False)\n",
    "            self._buffer = None\n",
    "        \n",
    "    @property\n",
    "    def state(self):\n",
    "        '''\n",
    "        Returns the dictionary containing important markers about the current frame(s).\n",
    "        '''\n",
    "        return self._state\n",
    "    \n",
    "    @state.setter\n",
    "    def state(self, state):\n",
    "        '''\n",
    "        Set important markers about the current frame(s).\n",
    "        \n",
    "        Contains information about the current environment that the camera \"sees\".\n",
    "        The state variable is necessary for validating the data later on.\n",
    "        '''\n",
    "        self._state = state\n",
    "        \n",
    "    @property\n",
    "    def decouple_queue(self):\n",
    "        '''\n",
    "        Returns if the queue is getting filled with frames.\n",
    "        '''\n",
    "        return self._disengage\n",
    "    \n",
    "    @decouple_queue.setter\n",
    "    def decouple_queue(self, val):\n",
    "        '''\n",
    "        Set whether to stop pushing to the queue or not. Can be set dynamically. \n",
    "        \n",
    "        Keyword params:\n",
    "        val -- True to put a halt on pushing frames and False for the opposite.\n",
    "        '''\n",
    "        self._disengage = val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraSource(Thread):\n",
    "    '''\n",
    "    Class used to gather BGR frames from the PiCamera on a separate thread while pushing them\n",
    "    in a queue that gets consumed on the fly by a process which analyses the data.\n",
    "    \n",
    "    Only one instance of this class can exist at a moment.\n",
    "    \n",
    "    The format of each pushed object into the queue is tailored for the GiggleBotQAValidation class. That is, each object (list)\n",
    "    contains a (captured) frame and metadata about it stored as a dictionary. This class can be adapted to accept any format for\n",
    "    these pushed objects.\n",
    "    '''\n",
    "    def __init__(self, queue, camera_settings, state = {}, output_resize = (480, 272)):\n",
    "        '''\n",
    "        Initialise the CameraSource object.\n",
    "        \n",
    "        Init params:\n",
    "        queue -- The queue into which frames are pushed in one by one. The queue needs to be infinite in size.\n",
    "        camera_settings -- Settings of the PiCamera that can be accessed as an attribute after having initialized the object.\n",
    "        state -- A dictionary containing important markers necessary for validating the data.\n",
    "        output_resize -- The actual resolution of the frames that get pushed into the queue. Must be >= than what's specified in camera_settings param. 2-element tuple of (width, height).\n",
    "        \n",
    "        The constructor waits 2 seconds for the camera to initialize \n",
    "        after the PiCamera object is created. This is a suggestion found in PiCamera's documentation.\n",
    "        \n",
    "        The output_resize param has to be a 2-element tuple containing the width and height of the recorded frames.\n",
    "        '''\n",
    "        super(CameraSource, self).__init__(group = None, target = None, name = 'CameraSource')\n",
    "        \n",
    "        self._queue = queue\n",
    "        self._camera_settings = camera_settings\n",
    "        self._output_resize = output_resize\n",
    "        self._output = MyOutput(queue, output_resize, state)\n",
    "        \n",
    "        self._stop_thread = False\n",
    "        self._terminated = False\n",
    "        \n",
    "        self.camera = picamera.PiCamera()\n",
    "        self.camera.start_preview()\n",
    "        for setting in list(camera_settings.keys()):\n",
    "           setattr(self.camera, setting, camera_settings[setting])\n",
    "        sleep(2.0)\n",
    "        \n",
    "    def run(self):\n",
    "        '''\n",
    "        This method must not be called from the user space. This gets called by the start method,\n",
    "        which in turn, is used to trigger this method.\n",
    "        \n",
    "        This method continuously pushes frames into the queue. To stop it, call the stop method.\n",
    "        '''\n",
    "        try:\n",
    "            self.camera.start_recording(self._output,\n",
    "                                        format = 'bgr',\n",
    "                                        resize = self._output_resize)\n",
    "            while self._stop_thread is False:\n",
    "                sleep(0.001)\n",
    "            self.camera.close()\n",
    "        except:\n",
    "            pass\n",
    "        finally:\n",
    "            self._terminated = True\n",
    "            \n",
    "    def stop(self, blocking = True):\n",
    "        '''\n",
    "        Stops the run method that got called by start method.\n",
    "        \n",
    "        Keyword params:\n",
    "        blocking -- Boolean to specify if it awaits for the run method to stop.\n",
    "        '''\n",
    "        self._stop_thread = True\n",
    "        if blocking is True:\n",
    "            while self._terminated is False:\n",
    "                sleep(0.001)\n",
    "                \n",
    "    @property\n",
    "    def state(self):\n",
    "        return self._output.state\n",
    "    \n",
    "    @state.setter\n",
    "    def state(self, state):\n",
    "        self._output.state = state\n",
    "        \n",
    "    @property\n",
    "    def pause(self):\n",
    "        '''\n",
    "        Checks if recording is paused or not.\n",
    "        '''\n",
    "        return self._output.decouple_queue\n",
    "    \n",
    "    @pause.setter\n",
    "    def pause(self, val):\n",
    "        '''\n",
    "        Pauses the recording process or resumes it.\n",
    "        \n",
    "        Keyword params:\n",
    "        val -- True to pause it and false to resume it.\n",
    "        '''\n",
    "        self._output.decouple_queue = val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GiggleBotQAValidation(Thread):\n",
    "    \n",
    "    failed_qa = False\n",
    "    counter = 0\n",
    "    \n",
    "    def __init__(self, process_queue, stop_when_empty = False):\n",
    "        super(GiggleBotQAValidation, self).__init__(group = None, target = None, name = 'GiggleBotQAValidation')\n",
    "        \n",
    "        self._procq = process_queue\n",
    "        self._stop_when_empty = stop_when_empty\n",
    "        self._stop_thread = False\n",
    "        self._terminated = False\n",
    "        self._boundaries = [\n",
    "            ('red', [0, 165, 128], [15, 255, 255]),\n",
    "            ('red', [165, 165, 128], [179, 255, 255]),\n",
    "            ('green', [35, 165, 128], [75, 255, 255]),\n",
    "            ('blue', [90, 165, 128], [133, 255, 255])\n",
    "        ]\n",
    "        \n",
    "    def run(self):\n",
    "        while self._stop_thread is False:\n",
    "            try:\n",
    "                frame, metadata = self._procq.get_nowait()\n",
    "                self._do_qa_on_frame(frame, metadata)\n",
    "            except Empty:\n",
    "                if self._stop_when_empty is True:\n",
    "                    break\n",
    "            finally:\n",
    "                sleep(0.001)\n",
    "        self._terminated = True\n",
    "    \n",
    "    def stop(self, blocking = True):\n",
    "        self._stop_thread = True\n",
    "        if blocking is True:\n",
    "            while self._terminated is False:\n",
    "                sleep(0.001)\n",
    "                \n",
    "    def _do_qa_on_frame(self, frame, metadata):\n",
    "        color_dist, leds = self._do_frame_analysis(frame)\n",
    "        print(color_dist, leds, self.counter)\n",
    "    \n",
    "    def _do_frame_analysis(self, frame):\n",
    "        (height, width) = frame.shape[0:2]\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        blurred = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
    "        contours = cv2.findContours(thresh[1].copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = contours[0] if imutils.is_cv2() else contours[1]\n",
    "        \n",
    "        contours_list = []\n",
    "        radiuses = []\n",
    "        centers = []\n",
    "        for contour in contours:\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.01 * perimeter, True, True)\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if (len(approx) > 8) and (len(approx) < 23) and area > 100:\n",
    "                contours_list.append(contour)\n",
    "                radiuses.append(perimeter / math.pi / 2)\n",
    "                M = cv2.moments(contour)\n",
    "                cX = int(M['m10'] / M['m00'])\n",
    "                cY = int(M['m01'] / M['m00'])\n",
    "                centers.append((cX, cY))\n",
    "        \n",
    "        scale = 1.7\n",
    "        intern_radius = np.mean(radiuses)\n",
    "        extern_radius = intern_radius * scale\n",
    "        intern_radius = math.ceil(intern_radius)\n",
    "        extern_radius = math.ceil(extern_radius)\n",
    "        extern_diam = extern_radius * 2\n",
    "        \n",
    "        mask = np.zeros((height, width, 3), np.uint8)\n",
    "        for center in centers:\n",
    "            cv2.circle(mask, center, extern_radius, (255, 255, 255), -1)\n",
    "            cv2.circle(mask, center, intern_radius, (0, 0, 0), -1)\n",
    "            \n",
    "        out = np.zeros((height, width, 3), np.uint8)\n",
    "        cv2.bitwise_and(frame, mask, out)\n",
    "        writearray(out[:,:,[2,1,0]], \"processed/img_{}.png\".format(self.counter), 'RGB')\n",
    "        self.counter += 1\n",
    "        cv2.cvtColor(out, cv2.COLOR_BGR2HSV, out)\n",
    "                         \n",
    "        transpose_list = list(zip(*self._boundaries))\n",
    "        colors = {}\n",
    "        for elem in transpose_list[0]:\n",
    "            colors[elem] = 0\n",
    "        for (color, lower, upper) in self._boundaries:\n",
    "            lower = np.array(lower, dtype = np.uint8)\n",
    "            upper = np.array(upper, dtype = np.uint8)\n",
    "            \n",
    "            mask = cv2.inRange(out, lower, upper)\n",
    "            filtered_channel = cv2.bitwise_and(out, out, mask = mask)\n",
    "            filtered_channel = filtered_channel.reshape((height * width, 3))\n",
    "            filtered_channel = filtered_channel[~np.all(filtered_channel == 0, axis = 1)]\n",
    "            colors[color] += filtered_channel.shape[0]\n",
    "            \n",
    "        return colors, len(contours_list)\n",
    "    \n",
    "def test(frame, metadata):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import IPython\n",
    "\n",
    "def imshow(a, fmt='jpeg'):\n",
    "    '''\n",
    "    Function to display an image within a Jupyter notebook.\n",
    "    \n",
    "    Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "    \n",
    "    Keyword params:\n",
    "    a -- numpy array to print; has width, height and no. of planes.\n",
    "    fmt -- output format to print; 'jpeg' is the fastest.\n",
    "    '''\n",
    "    f = io.BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    height = a.shape[0]\n",
    "    width = a.shape[1]\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue(), width = width, height = height))\n",
    "    \n",
    "    \n",
    "def writearray(array, filename, mode = 'RGB'):\n",
    "    img = Image.fromarray(array, mode)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img.save(filename)\n",
    "    \n",
    "def readarray(filename):\n",
    "    img = Image.open(filename)\n",
    "    imarray = np.array(img)\n",
    "    \n",
    "    return imarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pi/.env/lib/python3.5/site-packages/picamera/encoders.py:521: PiCameraAlphaStripping: using alpha-stripping to convert to non-alpha format; you may find the equivalent alpha format faster\n",
      "  \"using alpha-stripping to convert to non-alpha \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue': 0, 'green': 0, 'red': 4780} 7 1\n",
      "{'blue': 0, 'green': 0, 'red': 4767} 7 2\n",
      "{'blue': 0, 'green': 0, 'red': 4781} 7 3\n",
      "{'blue': 0, 'green': 0, 'red': 4776} 7 4\n",
      "{'blue': 0, 'green': 0, 'red': 4781} 7 5\n",
      "{'blue': 0, 'green': 0, 'red': 4773} 7 6\n",
      "{'blue': 0, 'green': 0, 'red': 4779} 7 7\n",
      "{'blue': 0, 'green': 0, 'red': 4770} 7 8\n",
      "{'blue': 0, 'green': 0, 'red': 4766} 7 9\n",
      "{'blue': 0, 'green': 0, 'red': 4772} 7 10\n",
      "{'blue': 0, 'green': 0, 'red': 4771} 7 11\n",
      "{'blue': 0, 'green': 0, 'red': 4771} 7 12\n",
      "{'blue': 0, 'green': 2342, 'red': 2193} 7 13\n",
      "{'blue': 0, 'green': 5496, 'red': 0} 7 14\n",
      "{'blue': 0, 'green': 5493, 'red': 0} 7 15\n",
      "{'blue': 0, 'green': 5487, 'red': 0} 7 16\n",
      "{'blue': 0, 'green': 5497, 'red': 0} 7 17\n",
      "{'blue': 0, 'green': 5489, 'red': 0} 7 18\n",
      "{'blue': 0, 'green': 5487, 'red': 0} 7 19\n",
      "{'blue': 0, 'green': 5486, 'red': 0} 7 20\n",
      "{'blue': 0, 'green': 5489, 'red': 0} 7 21\n",
      "{'blue': 0, 'green': 5493, 'red': 0} 7 22\n",
      "{'blue': 0, 'green': 5487, 'red': 0} 7 23\n",
      "{'blue': 0, 'green': 5497, 'red': 0} 7 24\n",
      "{'blue': 0, 'green': 5494, 'red': 0} 7 25\n",
      "{'blue': 0, 'green': 5485, 'red': 0} 7 26\n",
      "{'blue': 0, 'green': 5489, 'red': 0} 7 27\n",
      "{'blue': 0, 'green': 5498, 'red': 0} 7 28\n",
      "{'blue': 0, 'green': 5505, 'red': 0} 7 29\n",
      "{'blue': 0, 'green': 5501, 'red': 0} 7 30\n",
      "{'blue': 0, 'green': 5498, 'red': 0} 7 31\n",
      "{'blue': 0, 'green': 5503, 'red': 0} 7 32\n",
      "{'blue': 2021, 'green': 2389, 'red': 0} 7 33\n",
      "{'blue': 4878, 'green': 0, 'red': 0} 7 34\n",
      "{'blue': 4878, 'green': 0, 'red': 0} 7 35\n",
      "{'blue': 4881, 'green': 0, 'red': 0} 7 36\n",
      "{'blue': 4879, 'green': 0, 'red': 0} 7 37\n",
      "{'blue': 4879, 'green': 0, 'red': 0} 7 38\n",
      "{'blue': 4880, 'green': 0, 'red': 0} 7 39\n",
      "{'blue': 4878, 'green': 0, 'red': 0} 7 40\n",
      "{'blue': 4876, 'green': 0, 'red': 0} 7 41\n",
      "{'blue': 4880, 'green': 0, 'red': 0} 7 42\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    'iso': 100,\n",
    "    'shutter_speed': 48000,\n",
    "    'preview_alpha': 255,\n",
    "    'sensor_mode': 1,\n",
    "    'rotation': 0,\n",
    "    'framerate': 20,\n",
    "    'brightness': 50,\n",
    "    'awb_mode': 'off',\n",
    "    'awb_gains': 1.5\n",
    "}\n",
    "state = {\n",
    "    'leds': 'red'\n",
    "}\n",
    "image_queue = Queue(maxsize = -1)\n",
    "\n",
    "consumer = GiggleBotQAValidation(image_queue)\n",
    "producer = CameraSource(image_queue, settings, state)\n",
    "\n",
    "consumer.start()\n",
    "producer.start()\n",
    "sleep(3)\n",
    "producer.stop()\n",
    "sleep(15)\n",
    "consumer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writearray(frame, 'gb_red.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
